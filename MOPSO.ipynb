{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJCFy+fppXQ2e33lcgWbms",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuji-sgs/m1-reserch/blob/main/MOPSO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# はじめに\n",
        "\n",
        "## 本ノートブックの目的\n",
        "[前回作成したノートブック](https://github.com/yuji-sgs/m1-reserch/blob/main/Inverse_Analysis.ipynb)では深層学習モデルの1出力に対する逆解析にしか適応できなかったが、複数出力に対する逆解析を実現するために、KerasのFunctional APIを用いて複数出力の深層学習モデルを作成し、その学習済みモデルを適用して多目的粒子群最適化（MOPSO）アルゴリズムを構築していく。\n",
        "\n",
        "## 処理フロー\n",
        "1. 使用するライブラリをインポート\n",
        "2. データの読み込み・確認\n",
        "3. データ分割\n",
        "4. KerasのFunctional APIで学習\n",
        "5. 学習後の精度評価\n",
        "6. MOPSO実装"
      ],
      "metadata": {
        "id": "STfTJcJOhJom"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 使用するライブラリをインポート"
      ],
      "metadata": {
        "id": "wRR4YUktj86x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "u9sDra_qg27E"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from scipy.interpolate import griddata\n",
        "\n",
        "import io\n",
        "from google.colab import files\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from sklearn.metrics import r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. データの読み込み・確認\n",
        "ローカルにあるファイルからGoogle Colaboratoryにアップロード"
      ],
      "metadata": {
        "id": "mIbEW2MEkKs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Colaboratoryでファイルをアップロード\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "bTSO3UCyj_Zt",
        "outputId": "f8da9ecc-e6be-42b3-eea4-49001042b672"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0bd364e8-6816-4e07-9cf3-fcb7848903cb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0bd364e8-6816-4e07-9cf3-fcb7848903cb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data_Multiple.csv to data_Multiple.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# データフレームとして、変数dfに4列×10000行のデータを格納（C2：材料パラメータ, s：構造パラメータ, w11_max：遮音パラメータ1,　BandGap1：遮音パラメータ2）\n",
        "df = pd.read_csv(io.BytesIO(uploaded['data_Multiple.csv']))\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "CMaPN4UGkRh2",
        "outputId": "6497e040-5b5b-471c-ca2a-fb987e9db727"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         C2     s  w11_max      BandGap1\n",
              "0      0.15  0.01   250.00  6.689500e+00\n",
              "1      0.30  0.01   353.55  5.649800e+00\n",
              "2      0.45  0.01   433.01  4.264400e+00\n",
              "3      0.60  0.01   500.00  2.945800e+00\n",
              "4      0.75  0.01   559.02  1.748300e+00\n",
              "...     ...   ...      ...           ...\n",
              "9995  14.40  1.00   645.50  4.090000e-12\n",
              "9996  14.55  1.00   645.50  7.840000e-12\n",
              "9997  14.70  1.00   645.50  2.270000e-13\n",
              "9998  14.85  1.00   645.50  4.550000e-12\n",
              "9999  15.00  1.00   645.50  6.930000e-12\n",
              "\n",
              "[10000 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-066549f9-8e5c-4a1d-af9e-379cd1d3cb68\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C2</th>\n",
              "      <th>s</th>\n",
              "      <th>w11_max</th>\n",
              "      <th>BandGap1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.01</td>\n",
              "      <td>250.00</td>\n",
              "      <td>6.689500e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.30</td>\n",
              "      <td>0.01</td>\n",
              "      <td>353.55</td>\n",
              "      <td>5.649800e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.45</td>\n",
              "      <td>0.01</td>\n",
              "      <td>433.01</td>\n",
              "      <td>4.264400e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.60</td>\n",
              "      <td>0.01</td>\n",
              "      <td>500.00</td>\n",
              "      <td>2.945800e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.75</td>\n",
              "      <td>0.01</td>\n",
              "      <td>559.02</td>\n",
              "      <td>1.748300e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>14.40</td>\n",
              "      <td>1.00</td>\n",
              "      <td>645.50</td>\n",
              "      <td>4.090000e-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>14.55</td>\n",
              "      <td>1.00</td>\n",
              "      <td>645.50</td>\n",
              "      <td>7.840000e-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>14.70</td>\n",
              "      <td>1.00</td>\n",
              "      <td>645.50</td>\n",
              "      <td>2.270000e-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>14.85</td>\n",
              "      <td>1.00</td>\n",
              "      <td>645.50</td>\n",
              "      <td>4.550000e-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>15.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>645.50</td>\n",
              "      <td>6.930000e-12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-066549f9-8e5c-4a1d-af9e-379cd1d3cb68')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-066549f9-8e5c-4a1d-af9e-379cd1d3cb68 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-066549f9-8e5c-4a1d-af9e-379cd1d3cb68');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-391e0ded-3a29-4fe4-a284-001f44d901db\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-391e0ded-3a29-4fe4-a284-001f44d901db')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-391e0ded-3a29-4fe4-a284-001f44d901db button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. データ分割\n",
        "学習用データとテスト用データに分割"
      ],
      "metadata": {
        "id": "2ZLhGzO9lRlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データの分割\n",
        "(train, test) = train_test_split(df, test_size=0.2, shuffle=True)"
      ],
      "metadata": {
        "id": "dZJZum2rlbe9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train, x_testではcsvファイルの1, 2列目を， y_train, y_testでは3, 4列目のデータを活用\n",
        "x_train = train.iloc[:, [0, 1]]\n",
        "y_train = train.iloc[:, [2, 3]]\n",
        "\n",
        "x_test = test.iloc[:, [0, 1]]\n",
        "y_test = test.iloc[:, [2, 3]]"
      ],
      "metadata": {
        "id": "8miak9p1kVzV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. KerasのFunctional APIで学習\n",
        "### モデルの概要\n",
        "- 入力層：2ノード(C2, s)\n",
        "- 中間層：3層, 各層64ノード\n",
        "    - アウトプット直前の層にプラスで1層\n",
        "- 出力層：2ノード（w11_max, BandGap1）\n",
        "\n",
        "### 活性化関数\n",
        "- ReLUを採用（勾配消失問題の解消, 処理速度が速い, 多くの場合高い性能を示す）\n",
        "\n",
        "### 損失関数\n",
        "- 回帰問題に適したMSE（平均二乗誤差）を採用\n",
        "\n",
        "### 最適化アルゴリズム\n",
        "- Adamを採用（Kingma氏らが2014年に提案した高い性能を示すことで知られている | 参考：[Adam: A Method for Stochastic Optimization](https://www.semanticscholar.org/paper/Adam%3A-A-Method-for-Stochastic-Optimization-Kingma-Ba/a6cb366736791bcccc5c8639de5a8f9636bf87e8)）\n",
        "  - ハイパーパラメータは提案論文の推奨値で決定\n",
        "    - lr：学習率\n",
        "    - beta_1：過去の勾配の指数移動平均を計算する際の減衰係数\n",
        "    - beta_2：過去の勾配の二乗の指数移動平均を計算する際の減衰係数\n",
        "\n",
        "### その他ハイパーパラメータ\n",
        "- 学習回数：300回\n",
        "- バッチサイズ：64"
      ],
      "metadata": {
        "id": "Xf21pQ5rlydT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの構築\n",
        "# inputの数:C2, s\n",
        "inputs = Input(shape=(2,))\n",
        "\n",
        "# 学習回数\n",
        "epochs = 300\n",
        "batch_size = 64\n",
        "\n",
        "# ノード数\n",
        "node = 64\n",
        "\n",
        "x1 = Dense(node, activation='relu')(inputs)\n",
        "x2 = Dense(node, activation='relu')(x1)\n",
        "x3 = Dense(node, activation='relu')(x2)\n",
        "\n",
        "\n",
        "x4 = Dense(node, activation='relu')(x3) # アウトプット直前の層\n",
        "output1 = Dense(1, name='output1')(x4)\n",
        "\n",
        "x5 = Dense(node, activation='relu')(x3) # アウトプット直前の層\n",
        "output2 = Dense(1, name='output2')(x5)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=[output1, output2])\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=['mse', 'mse']\n",
        ")"
      ],
      "metadata": {
        "id": "NGsJF5uXlqhh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習オプション\n",
        "history = model.fit(x_train,\n",
        "                    {\"output1\":y_train.iloc[:, [0]], \"output2\":y_train.iloc[:, [1]]},\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(x_test, {\"output1\":y_test.iloc[:, [0]], \"output2\":y_test.iloc[:, [1]]})\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdV1zp7hneWG",
        "outputId": "8d4c8a7d-44fd-46e0-fe30-53b911deb47b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "125/125 [==============================] - 3s 8ms/step - loss: 576034.0625 - output1_loss: 432284.7500 - output2_loss: 143749.2188 - val_loss: 223910.2344 - val_output1_loss: 147560.3438 - val_output2_loss: 76349.9609\n",
            "Epoch 2/300\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 208299.5625 - output1_loss: 127994.9609 - output2_loss: 80304.6328 - val_loss: 183188.8125 - val_output1_loss: 103770.1875 - val_output2_loss: 79418.6562\n",
            "Epoch 3/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 171826.7031 - output1_loss: 91252.0156 - output2_loss: 80574.6328 - val_loss: 145804.9219 - val_output1_loss: 70467.2812 - val_output2_loss: 75337.6328\n",
            "Epoch 4/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 131355.3906 - output1_loss: 58854.1914 - output2_loss: 72501.2500 - val_loss: 105084.5234 - val_output1_loss: 41464.0664 - val_output2_loss: 63620.4297\n",
            "Epoch 5/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 99798.5156 - output1_loss: 39232.9297 - output2_loss: 60565.5898 - val_loss: 87205.3594 - val_output1_loss: 33359.4492 - val_output2_loss: 53845.8945\n",
            "Epoch 6/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 86333.8516 - output1_loss: 32688.7051 - output2_loss: 53645.1367 - val_loss: 75242.9688 - val_output1_loss: 28155.5352 - val_output2_loss: 47087.4336\n",
            "Epoch 7/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 74170.9375 - output1_loss: 27745.6680 - output2_loss: 46425.2812 - val_loss: 64767.3516 - val_output1_loss: 24162.4453 - val_output2_loss: 40604.9062\n",
            "Epoch 8/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 64986.9844 - output1_loss: 24340.0840 - output2_loss: 40646.8945 - val_loss: 54919.1445 - val_output1_loss: 20711.1934 - val_output2_loss: 34207.9531\n",
            "Epoch 9/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 55680.6484 - output1_loss: 22560.3965 - output2_loss: 33120.2617 - val_loss: 46380.9453 - val_output1_loss: 20069.1328 - val_output2_loss: 26311.8105\n",
            "Epoch 10/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 46651.8477 - output1_loss: 21022.2852 - output2_loss: 25629.5547 - val_loss: 37706.5078 - val_output1_loss: 18453.1172 - val_output2_loss: 19253.3926\n",
            "Epoch 11/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 36713.3633 - output1_loss: 17170.8125 - output2_loss: 19542.5566 - val_loss: 29116.4629 - val_output1_loss: 13862.0605 - val_output2_loss: 15254.3994\n",
            "Epoch 12/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 26839.7227 - output1_loss: 12617.2568 - output2_loss: 14222.4688 - val_loss: 20469.3730 - val_output1_loss: 10107.0537 - val_output2_loss: 10362.3164\n",
            "Epoch 13/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 18711.3809 - output1_loss: 8841.0908 - output2_loss: 9870.2812 - val_loss: 14861.0264 - val_output1_loss: 6553.1230 - val_output2_loss: 8307.9043\n",
            "Epoch 14/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 12241.1377 - output1_loss: 5951.1704 - output2_loss: 6289.9702 - val_loss: 9806.8242 - val_output1_loss: 4629.8833 - val_output2_loss: 5176.9404\n",
            "Epoch 15/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 8350.1406 - output1_loss: 4054.7734 - output2_loss: 4295.3633 - val_loss: 7948.1245 - val_output1_loss: 3719.0579 - val_output2_loss: 4229.0659\n",
            "Epoch 16/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 5722.9702 - output1_loss: 2854.5662 - output2_loss: 2868.4021 - val_loss: 4788.1924 - val_output1_loss: 2290.9641 - val_output2_loss: 2497.2292\n",
            "Epoch 17/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 3979.4067 - output1_loss: 1984.6896 - output2_loss: 1994.7173 - val_loss: 3053.9968 - val_output1_loss: 1412.0389 - val_output2_loss: 1641.9579\n",
            "Epoch 18/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 2843.2544 - output1_loss: 1413.2135 - output2_loss: 1430.0399 - val_loss: 2737.7307 - val_output1_loss: 1293.2760 - val_output2_loss: 1444.4546\n",
            "Epoch 19/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 2444.8870 - output1_loss: 1160.4398 - output2_loss: 1284.4476 - val_loss: 2010.4275 - val_output1_loss: 1024.7269 - val_output2_loss: 985.7008\n",
            "Epoch 20/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1865.8064 - output1_loss: 873.5317 - output2_loss: 992.2751 - val_loss: 2080.7798 - val_output1_loss: 1147.8658 - val_output2_loss: 932.9137\n",
            "Epoch 21/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1679.7207 - output1_loss: 791.4720 - output2_loss: 888.2489 - val_loss: 1407.1240 - val_output1_loss: 581.4819 - val_output2_loss: 825.6423\n",
            "Epoch 22/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1287.1292 - output1_loss: 548.0094 - output2_loss: 739.1197 - val_loss: 1268.1805 - val_output1_loss: 484.9135 - val_output2_loss: 783.2670\n",
            "Epoch 23/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1185.3783 - output1_loss: 519.0394 - output2_loss: 666.3389 - val_loss: 1189.5035 - val_output1_loss: 487.2275 - val_output2_loss: 702.2759\n",
            "Epoch 24/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1105.1133 - output1_loss: 502.6389 - output2_loss: 602.4739 - val_loss: 1251.2112 - val_output1_loss: 643.4825 - val_output2_loss: 607.7285\n",
            "Epoch 25/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1194.3734 - output1_loss: 571.7763 - output2_loss: 622.5969 - val_loss: 921.4078 - val_output1_loss: 342.7914 - val_output2_loss: 578.6165\n",
            "Epoch 26/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 910.7784 - output1_loss: 372.9343 - output2_loss: 537.8441 - val_loss: 1091.7356 - val_output1_loss: 584.3133 - val_output2_loss: 507.4221\n",
            "Epoch 27/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 889.2431 - output1_loss: 384.1580 - output2_loss: 505.0850 - val_loss: 826.3954 - val_output1_loss: 337.0652 - val_output2_loss: 489.3300\n",
            "Epoch 28/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 764.1899 - output1_loss: 319.8034 - output2_loss: 444.3864 - val_loss: 775.6022 - val_output1_loss: 351.3370 - val_output2_loss: 424.2653\n",
            "Epoch 29/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 718.6478 - output1_loss: 292.4128 - output2_loss: 426.2346 - val_loss: 680.6004 - val_output1_loss: 249.7375 - val_output2_loss: 430.8629\n",
            "Epoch 30/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 617.6216 - output1_loss: 244.2720 - output2_loss: 373.3495 - val_loss: 735.3699 - val_output1_loss: 250.3248 - val_output2_loss: 485.0452\n",
            "Epoch 31/300\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 646.9893 - output1_loss: 272.3326 - output2_loss: 374.6567 - val_loss: 701.0897 - val_output1_loss: 328.1978 - val_output2_loss: 372.8918\n",
            "Epoch 32/300\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 635.6991 - output1_loss: 279.0605 - output2_loss: 356.6387 - val_loss: 589.3902 - val_output1_loss: 233.3287 - val_output2_loss: 356.0615\n",
            "Epoch 33/300\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 565.3041 - output1_loss: 248.8800 - output2_loss: 316.4241 - val_loss: 570.2258 - val_output1_loss: 255.6817 - val_output2_loss: 314.5440\n",
            "Epoch 34/300\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 546.3383 - output1_loss: 232.1893 - output2_loss: 314.1492 - val_loss: 521.9457 - val_output1_loss: 224.9795 - val_output2_loss: 296.9662\n",
            "Epoch 35/300\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 586.2436 - output1_loss: 264.3675 - output2_loss: 321.8761 - val_loss: 490.8940 - val_output1_loss: 203.9148 - val_output2_loss: 286.9792\n",
            "Epoch 36/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 572.8922 - output1_loss: 286.3529 - output2_loss: 286.5393 - val_loss: 702.6845 - val_output1_loss: 366.5089 - val_output2_loss: 336.1755\n",
            "Epoch 37/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 501.5418 - output1_loss: 235.7152 - output2_loss: 265.8266 - val_loss: 585.5035 - val_output1_loss: 211.5780 - val_output2_loss: 373.9256\n",
            "Epoch 38/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 443.2172 - output1_loss: 201.6354 - output2_loss: 241.5817 - val_loss: 499.9041 - val_output1_loss: 215.0333 - val_output2_loss: 284.8708\n",
            "Epoch 39/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 459.9107 - output1_loss: 218.1898 - output2_loss: 241.7211 - val_loss: 400.7550 - val_output1_loss: 179.4595 - val_output2_loss: 221.2955\n",
            "Epoch 40/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 437.4489 - output1_loss: 206.0558 - output2_loss: 231.3931 - val_loss: 393.7253 - val_output1_loss: 181.2366 - val_output2_loss: 212.4887\n",
            "Epoch 41/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 398.1273 - output1_loss: 187.3873 - output2_loss: 210.7400 - val_loss: 384.8731 - val_output1_loss: 178.6295 - val_output2_loss: 206.2436\n",
            "Epoch 42/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 384.2397 - output1_loss: 178.0250 - output2_loss: 206.2146 - val_loss: 557.1929 - val_output1_loss: 334.9991 - val_output2_loss: 222.1938\n",
            "Epoch 43/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 436.4690 - output1_loss: 222.1461 - output2_loss: 214.3229 - val_loss: 726.5662 - val_output1_loss: 445.4475 - val_output2_loss: 281.1187\n",
            "Epoch 44/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 472.7390 - output1_loss: 235.1912 - output2_loss: 237.5478 - val_loss: 416.3191 - val_output1_loss: 168.5153 - val_output2_loss: 247.8038\n",
            "Epoch 45/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 425.2236 - output1_loss: 211.9862 - output2_loss: 213.2374 - val_loss: 332.4755 - val_output1_loss: 157.5566 - val_output2_loss: 174.9190\n",
            "Epoch 46/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 354.6305 - output1_loss: 188.5596 - output2_loss: 166.0709 - val_loss: 332.1425 - val_output1_loss: 159.8315 - val_output2_loss: 172.3110\n",
            "Epoch 47/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 350.1815 - output1_loss: 182.8338 - output2_loss: 167.3477 - val_loss: 324.2624 - val_output1_loss: 148.7370 - val_output2_loss: 175.5253\n",
            "Epoch 48/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 321.8563 - output1_loss: 163.8244 - output2_loss: 158.0319 - val_loss: 329.1960 - val_output1_loss: 144.5909 - val_output2_loss: 184.6051\n",
            "Epoch 49/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 308.5919 - output1_loss: 160.1307 - output2_loss: 148.4612 - val_loss: 287.2619 - val_output1_loss: 148.4037 - val_output2_loss: 138.8582\n",
            "Epoch 50/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 339.8155 - output1_loss: 185.6155 - output2_loss: 154.2000 - val_loss: 506.4845 - val_output1_loss: 170.0423 - val_output2_loss: 336.4423\n",
            "Epoch 51/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 311.1781 - output1_loss: 164.6623 - output2_loss: 146.5157 - val_loss: 279.6335 - val_output1_loss: 140.4453 - val_output2_loss: 139.1882\n",
            "Epoch 52/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 411.6912 - output1_loss: 257.2996 - output2_loss: 154.3915 - val_loss: 289.6542 - val_output1_loss: 143.7919 - val_output2_loss: 145.8623\n",
            "Epoch 53/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 350.1775 - output1_loss: 202.6877 - output2_loss: 147.4898 - val_loss: 374.6863 - val_output1_loss: 206.6617 - val_output2_loss: 168.0245\n",
            "Epoch 54/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 325.7163 - output1_loss: 193.4144 - output2_loss: 132.3020 - val_loss: 277.9275 - val_output1_loss: 141.7745 - val_output2_loss: 136.1530\n",
            "Epoch 55/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 301.9614 - output1_loss: 169.6393 - output2_loss: 132.3222 - val_loss: 297.0354 - val_output1_loss: 163.9418 - val_output2_loss: 133.0936\n",
            "Epoch 56/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 271.9916 - output1_loss: 146.6040 - output2_loss: 125.3876 - val_loss: 253.5006 - val_output1_loss: 145.5077 - val_output2_loss: 107.9930\n",
            "Epoch 57/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 242.0643 - output1_loss: 139.3807 - output2_loss: 102.6835 - val_loss: 243.9433 - val_output1_loss: 127.8127 - val_output2_loss: 116.1305\n",
            "Epoch 58/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 263.5443 - output1_loss: 147.4469 - output2_loss: 116.0975 - val_loss: 314.1295 - val_output1_loss: 171.3692 - val_output2_loss: 142.7604\n",
            "Epoch 59/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 228.9839 - output1_loss: 126.4542 - output2_loss: 102.5297 - val_loss: 308.0350 - val_output1_loss: 186.0530 - val_output2_loss: 121.9821\n",
            "Epoch 60/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 304.9810 - output1_loss: 167.0833 - output2_loss: 137.8978 - val_loss: 244.1820 - val_output1_loss: 132.1719 - val_output2_loss: 112.0101\n",
            "Epoch 61/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 254.3478 - output1_loss: 142.2317 - output2_loss: 112.1161 - val_loss: 281.4705 - val_output1_loss: 176.7478 - val_output2_loss: 104.7228\n",
            "Epoch 62/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 251.8557 - output1_loss: 145.9470 - output2_loss: 105.9087 - val_loss: 223.2214 - val_output1_loss: 132.6471 - val_output2_loss: 90.5744\n",
            "Epoch 63/300\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 243.2671 - output1_loss: 135.5848 - output2_loss: 107.6822 - val_loss: 271.3866 - val_output1_loss: 171.7144 - val_output2_loss: 99.6722\n",
            "Epoch 64/300\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 256.5484 - output1_loss: 143.0428 - output2_loss: 113.5056 - val_loss: 830.4939 - val_output1_loss: 472.1744 - val_output2_loss: 358.3194\n",
            "Epoch 65/300\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 264.3711 - output1_loss: 156.4534 - output2_loss: 107.9178 - val_loss: 220.7587 - val_output1_loss: 123.5075 - val_output2_loss: 97.2512\n",
            "Epoch 66/300\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 281.7538 - output1_loss: 158.7152 - output2_loss: 123.0385 - val_loss: 250.1241 - val_output1_loss: 159.0329 - val_output2_loss: 91.0913\n",
            "Epoch 67/300\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 225.1341 - output1_loss: 126.8357 - output2_loss: 98.2983 - val_loss: 259.7524 - val_output1_loss: 147.4698 - val_output2_loss: 112.2826\n",
            "Epoch 68/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 242.7055 - output1_loss: 142.0394 - output2_loss: 100.6662 - val_loss: 185.2683 - val_output1_loss: 108.3181 - val_output2_loss: 76.9502\n",
            "Epoch 69/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 220.9535 - output1_loss: 134.7671 - output2_loss: 86.1864 - val_loss: 238.7821 - val_output1_loss: 128.2379 - val_output2_loss: 110.5443\n",
            "Epoch 70/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 227.0124 - output1_loss: 127.1960 - output2_loss: 99.8164 - val_loss: 220.0664 - val_output1_loss: 144.3985 - val_output2_loss: 75.6679\n",
            "Epoch 71/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 281.4471 - output1_loss: 168.4837 - output2_loss: 112.9632 - val_loss: 262.9935 - val_output1_loss: 186.5112 - val_output2_loss: 76.4824\n",
            "Epoch 72/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 240.9633 - output1_loss: 145.2941 - output2_loss: 95.6692 - val_loss: 197.0757 - val_output1_loss: 108.5746 - val_output2_loss: 88.5011\n",
            "Epoch 73/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 180.7425 - output1_loss: 107.1743 - output2_loss: 73.5681 - val_loss: 171.5042 - val_output1_loss: 101.6247 - val_output2_loss: 69.8794\n",
            "Epoch 74/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 184.1965 - output1_loss: 110.7459 - output2_loss: 73.4506 - val_loss: 172.9227 - val_output1_loss: 101.3107 - val_output2_loss: 71.6120\n",
            "Epoch 75/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 173.3473 - output1_loss: 102.2624 - output2_loss: 71.0849 - val_loss: 208.2492 - val_output1_loss: 121.0128 - val_output2_loss: 87.2364\n",
            "Epoch 76/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 186.0206 - output1_loss: 109.0522 - output2_loss: 76.9683 - val_loss: 186.6816 - val_output1_loss: 113.0790 - val_output2_loss: 73.6026\n",
            "Epoch 77/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 202.9662 - output1_loss: 118.2869 - output2_loss: 84.6794 - val_loss: 207.1110 - val_output1_loss: 144.1987 - val_output2_loss: 62.9123\n",
            "Epoch 78/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 169.3125 - output1_loss: 97.8089 - output2_loss: 71.5035 - val_loss: 167.8039 - val_output1_loss: 94.0654 - val_output2_loss: 73.7385\n",
            "Epoch 79/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 211.2320 - output1_loss: 130.4834 - output2_loss: 80.7486 - val_loss: 362.0387 - val_output1_loss: 261.0919 - val_output2_loss: 100.9468\n",
            "Epoch 80/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 171.8515 - output1_loss: 100.7123 - output2_loss: 71.1392 - val_loss: 158.8894 - val_output1_loss: 91.4989 - val_output2_loss: 67.3904\n",
            "Epoch 81/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 419.6781 - output1_loss: 234.3930 - output2_loss: 185.2852 - val_loss: 485.6829 - val_output1_loss: 371.9171 - val_output2_loss: 113.7658\n",
            "Epoch 82/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 240.9023 - output1_loss: 141.8150 - output2_loss: 99.0873 - val_loss: 194.6537 - val_output1_loss: 103.3407 - val_output2_loss: 91.3130\n",
            "Epoch 83/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 198.7971 - output1_loss: 115.4841 - output2_loss: 83.3131 - val_loss: 187.0471 - val_output1_loss: 112.8673 - val_output2_loss: 74.1798\n",
            "Epoch 84/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 227.4636 - output1_loss: 144.4027 - output2_loss: 83.0609 - val_loss: 184.0837 - val_output1_loss: 88.2283 - val_output2_loss: 95.8554\n",
            "Epoch 85/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 226.0855 - output1_loss: 130.6129 - output2_loss: 95.4726 - val_loss: 159.5747 - val_output1_loss: 97.3054 - val_output2_loss: 62.2693\n",
            "Epoch 86/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 141.9659 - output1_loss: 84.3329 - output2_loss: 57.6329 - val_loss: 146.5229 - val_output1_loss: 86.6075 - val_output2_loss: 59.9154\n",
            "Epoch 87/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 152.0734 - output1_loss: 88.2963 - output2_loss: 63.7771 - val_loss: 154.7217 - val_output1_loss: 89.4750 - val_output2_loss: 65.2467\n",
            "Epoch 88/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 159.5082 - output1_loss: 95.1332 - output2_loss: 64.3750 - val_loss: 162.8536 - val_output1_loss: 105.7442 - val_output2_loss: 57.1094\n",
            "Epoch 89/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 136.4781 - output1_loss: 79.5266 - output2_loss: 56.9516 - val_loss: 142.3524 - val_output1_loss: 82.1293 - val_output2_loss: 60.2230\n",
            "Epoch 90/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 144.5119 - output1_loss: 83.7479 - output2_loss: 60.7640 - val_loss: 142.7151 - val_output1_loss: 79.9937 - val_output2_loss: 62.7215\n",
            "Epoch 91/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 150.1183 - output1_loss: 85.6275 - output2_loss: 64.4908 - val_loss: 130.7089 - val_output1_loss: 79.8981 - val_output2_loss: 50.8109\n",
            "Epoch 92/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 148.4176 - output1_loss: 85.1348 - output2_loss: 63.2829 - val_loss: 162.2777 - val_output1_loss: 94.7926 - val_output2_loss: 67.4851\n",
            "Epoch 93/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 159.6992 - output1_loss: 90.7336 - output2_loss: 68.9655 - val_loss: 165.3027 - val_output1_loss: 79.5691 - val_output2_loss: 85.7336\n",
            "Epoch 94/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 324.9899 - output1_loss: 184.3226 - output2_loss: 140.6672 - val_loss: 180.4812 - val_output1_loss: 119.0846 - val_output2_loss: 61.3966\n",
            "Epoch 95/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 184.9589 - output1_loss: 103.6561 - output2_loss: 81.3027 - val_loss: 220.8471 - val_output1_loss: 104.8163 - val_output2_loss: 116.0308\n",
            "Epoch 96/300\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 149.4929 - output1_loss: 85.4562 - output2_loss: 64.0366 - val_loss: 158.7557 - val_output1_loss: 82.0440 - val_output2_loss: 76.7117\n",
            "Epoch 97/300\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 157.7571 - output1_loss: 87.7209 - output2_loss: 70.0361 - val_loss: 278.3341 - val_output1_loss: 226.6367 - val_output2_loss: 51.6974\n",
            "Epoch 98/300\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 164.0717 - output1_loss: 100.2763 - output2_loss: 63.7954 - val_loss: 137.4789 - val_output1_loss: 72.8350 - val_output2_loss: 64.6439\n",
            "Epoch 99/300\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 130.9245 - output1_loss: 75.2853 - output2_loss: 55.6392 - val_loss: 132.5650 - val_output1_loss: 74.4712 - val_output2_loss: 58.0938\n",
            "Epoch 100/300\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 145.2587 - output1_loss: 84.2040 - output2_loss: 61.0548 - val_loss: 144.5887 - val_output1_loss: 82.2518 - val_output2_loss: 62.3369\n",
            "Epoch 101/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 122.7127 - output1_loss: 71.9139 - output2_loss: 50.7988 - val_loss: 150.8354 - val_output1_loss: 97.3598 - val_output2_loss: 53.4756\n",
            "Epoch 102/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 152.8070 - output1_loss: 89.8376 - output2_loss: 62.9694 - val_loss: 146.7212 - val_output1_loss: 85.2141 - val_output2_loss: 61.5072\n",
            "Epoch 103/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 179.4852 - output1_loss: 106.4919 - output2_loss: 72.9933 - val_loss: 218.6356 - val_output1_loss: 92.7884 - val_output2_loss: 125.8473\n",
            "Epoch 104/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 186.4162 - output1_loss: 108.8985 - output2_loss: 77.5177 - val_loss: 148.2835 - val_output1_loss: 77.7990 - val_output2_loss: 70.4845\n",
            "Epoch 105/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 334.5379 - output1_loss: 172.3468 - output2_loss: 162.1911 - val_loss: 142.8501 - val_output1_loss: 91.7616 - val_output2_loss: 51.0885\n",
            "Epoch 106/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 114.1093 - output1_loss: 66.6332 - output2_loss: 47.4761 - val_loss: 130.7813 - val_output1_loss: 72.8003 - val_output2_loss: 57.9810\n",
            "Epoch 107/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 141.0077 - output1_loss: 76.4033 - output2_loss: 64.6044 - val_loss: 141.9829 - val_output1_loss: 90.9741 - val_output2_loss: 51.0088\n",
            "Epoch 108/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 130.6696 - output1_loss: 73.9494 - output2_loss: 56.7202 - val_loss: 124.1185 - val_output1_loss: 69.9740 - val_output2_loss: 54.1445\n",
            "Epoch 109/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 116.6788 - output1_loss: 66.4460 - output2_loss: 50.2327 - val_loss: 122.4008 - val_output1_loss: 65.9847 - val_output2_loss: 56.4161\n",
            "Epoch 110/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 232.8195 - output1_loss: 130.0123 - output2_loss: 102.8072 - val_loss: 144.7393 - val_output1_loss: 78.2184 - val_output2_loss: 66.5209\n",
            "Epoch 111/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 138.5185 - output1_loss: 74.4373 - output2_loss: 64.0812 - val_loss: 151.9673 - val_output1_loss: 82.2713 - val_output2_loss: 69.6960\n",
            "Epoch 112/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 123.3038 - output1_loss: 67.7813 - output2_loss: 55.5225 - val_loss: 112.8580 - val_output1_loss: 61.9183 - val_output2_loss: 50.9396\n",
            "Epoch 113/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 131.3395 - output1_loss: 74.4523 - output2_loss: 56.8872 - val_loss: 133.4804 - val_output1_loss: 80.5494 - val_output2_loss: 52.9310\n",
            "Epoch 114/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 128.5310 - output1_loss: 70.0130 - output2_loss: 58.5180 - val_loss: 130.4500 - val_output1_loss: 70.5247 - val_output2_loss: 59.9254\n",
            "Epoch 115/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 114.6101 - output1_loss: 64.9291 - output2_loss: 49.6809 - val_loss: 156.3137 - val_output1_loss: 79.0388 - val_output2_loss: 77.2749\n",
            "Epoch 116/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 133.1328 - output1_loss: 72.1456 - output2_loss: 60.9873 - val_loss: 108.9538 - val_output1_loss: 62.1769 - val_output2_loss: 46.7768\n",
            "Epoch 117/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 116.8627 - output1_loss: 64.0714 - output2_loss: 52.7913 - val_loss: 138.0562 - val_output1_loss: 76.7858 - val_output2_loss: 61.2704\n",
            "Epoch 118/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 141.5554 - output1_loss: 81.0427 - output2_loss: 60.5127 - val_loss: 261.5604 - val_output1_loss: 66.1775 - val_output2_loss: 195.3829\n",
            "Epoch 119/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 178.0133 - output1_loss: 91.8633 - output2_loss: 86.1500 - val_loss: 138.2088 - val_output1_loss: 67.3895 - val_output2_loss: 70.8193\n",
            "Epoch 120/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 114.7375 - output1_loss: 65.6104 - output2_loss: 49.1270 - val_loss: 125.2994 - val_output1_loss: 69.1973 - val_output2_loss: 56.1020\n",
            "Epoch 121/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 118.4098 - output1_loss: 65.3466 - output2_loss: 53.0631 - val_loss: 109.6376 - val_output1_loss: 56.9279 - val_output2_loss: 52.7097\n",
            "Epoch 122/300\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 120.0736 - output1_loss: 70.5171 - output2_loss: 49.5566 - val_loss: 145.9611 - val_output1_loss: 75.6441 - val_output2_loss: 70.3170\n",
            "Epoch 123/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 138.6275 - output1_loss: 77.3346 - output2_loss: 61.2929 - val_loss: 424.4983 - val_output1_loss: 363.1041 - val_output2_loss: 61.3943\n",
            "Epoch 124/300\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 157.1330 - output1_loss: 88.1056 - output2_loss: 69.0274 - val_loss: 105.9599 - val_output1_loss: 61.8522 - val_output2_loss: 44.1077\n",
            "Epoch 125/300\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 103.2063 - output1_loss: 57.6813 - output2_loss: 45.5249 - val_loss: 107.5580 - val_output1_loss: 60.0360 - val_output2_loss: 47.5220\n",
            "Epoch 126/300\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 142.7451 - output1_loss: 76.2443 - output2_loss: 66.5007 - val_loss: 243.5689 - val_output1_loss: 84.0467 - val_output2_loss: 159.5222\n",
            "Epoch 127/300\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 132.5488 - output1_loss: 71.4906 - output2_loss: 61.0582 - val_loss: 102.7862 - val_output1_loss: 56.0965 - val_output2_loss: 46.6897\n",
            "Epoch 128/300\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 105.5746 - output1_loss: 57.5611 - output2_loss: 48.0134 - val_loss: 118.0936 - val_output1_loss: 60.2636 - val_output2_loss: 57.8300\n",
            "Epoch 129/300\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 378.3628 - output1_loss: 187.6090 - output2_loss: 190.7537 - val_loss: 882.0333 - val_output1_loss: 288.3716 - val_output2_loss: 593.6615\n",
            "Epoch 130/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 129.7137 - output1_loss: 69.9451 - output2_loss: 59.7687 - val_loss: 91.6102 - val_output1_loss: 52.9296 - val_output2_loss: 38.6805\n",
            "Epoch 131/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 96.4736 - output1_loss: 53.8377 - output2_loss: 42.6358 - val_loss: 98.3719 - val_output1_loss: 55.8343 - val_output2_loss: 42.5376\n",
            "Epoch 132/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 93.4926 - output1_loss: 52.7120 - output2_loss: 40.7806 - val_loss: 95.2021 - val_output1_loss: 56.2471 - val_output2_loss: 38.9550\n",
            "Epoch 133/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 108.2348 - output1_loss: 59.0892 - output2_loss: 49.1455 - val_loss: 130.7287 - val_output1_loss: 78.8631 - val_output2_loss: 51.8657\n",
            "Epoch 134/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 103.4050 - output1_loss: 57.2921 - output2_loss: 46.1129 - val_loss: 179.5841 - val_output1_loss: 52.4168 - val_output2_loss: 127.1673\n",
            "Epoch 135/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 128.5924 - output1_loss: 69.9234 - output2_loss: 58.6690 - val_loss: 95.0810 - val_output1_loss: 54.3898 - val_output2_loss: 40.6912\n",
            "Epoch 136/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 111.0791 - output1_loss: 60.0751 - output2_loss: 51.0040 - val_loss: 189.7202 - val_output1_loss: 126.3085 - val_output2_loss: 63.4117\n",
            "Epoch 137/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 104.2575 - output1_loss: 59.1151 - output2_loss: 45.1424 - val_loss: 92.9598 - val_output1_loss: 52.5117 - val_output2_loss: 40.4481\n",
            "Epoch 138/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 93.1445 - output1_loss: 49.7915 - output2_loss: 43.3530 - val_loss: 111.2568 - val_output1_loss: 58.1025 - val_output2_loss: 53.1543\n",
            "Epoch 139/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 110.6724 - output1_loss: 60.1207 - output2_loss: 50.5517 - val_loss: 226.0271 - val_output1_loss: 65.0803 - val_output2_loss: 160.9467\n",
            "Epoch 140/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 143.8999 - output1_loss: 69.6386 - output2_loss: 74.2615 - val_loss: 114.5435 - val_output1_loss: 59.2595 - val_output2_loss: 55.2841\n",
            "Epoch 141/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 102.4276 - output1_loss: 56.8808 - output2_loss: 45.5469 - val_loss: 105.3395 - val_output1_loss: 60.3418 - val_output2_loss: 44.9976\n",
            "Epoch 142/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 105.3369 - output1_loss: 55.4828 - output2_loss: 49.8541 - val_loss: 93.2038 - val_output1_loss: 53.1738 - val_output2_loss: 40.0300\n",
            "Epoch 143/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 135.5626 - output1_loss: 78.0057 - output2_loss: 57.5568 - val_loss: 125.7707 - val_output1_loss: 83.8531 - val_output2_loss: 41.9176\n",
            "Epoch 144/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 122.0608 - output1_loss: 64.3827 - output2_loss: 57.6781 - val_loss: 96.9826 - val_output1_loss: 51.1329 - val_output2_loss: 45.8496\n",
            "Epoch 145/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 119.2246 - output1_loss: 61.7652 - output2_loss: 57.4593 - val_loss: 95.3130 - val_output1_loss: 54.1288 - val_output2_loss: 41.1842\n",
            "Epoch 146/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 115.0981 - output1_loss: 61.6890 - output2_loss: 53.4091 - val_loss: 218.1309 - val_output1_loss: 93.7147 - val_output2_loss: 124.4162\n",
            "Epoch 147/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 105.0763 - output1_loss: 55.4884 - output2_loss: 49.5878 - val_loss: 126.2606 - val_output1_loss: 77.6615 - val_output2_loss: 48.5991\n",
            "Epoch 148/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 124.2804 - output1_loss: 68.3573 - output2_loss: 55.9232 - val_loss: 85.9849 - val_output1_loss: 47.5380 - val_output2_loss: 38.4469\n",
            "Epoch 149/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 110.9350 - output1_loss: 58.8207 - output2_loss: 52.1144 - val_loss: 94.8778 - val_output1_loss: 50.9330 - val_output2_loss: 43.9447\n",
            "Epoch 150/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 176.5265 - output1_loss: 94.6725 - output2_loss: 81.8541 - val_loss: 170.0512 - val_output1_loss: 71.0879 - val_output2_loss: 98.9632\n",
            "Epoch 151/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 179.6454 - output1_loss: 99.6211 - output2_loss: 80.0244 - val_loss: 467.9695 - val_output1_loss: 94.2256 - val_output2_loss: 373.7438\n",
            "Epoch 152/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 141.8261 - output1_loss: 68.3455 - output2_loss: 73.4806 - val_loss: 91.2048 - val_output1_loss: 47.5419 - val_output2_loss: 43.6629\n",
            "Epoch 153/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 121.0404 - output1_loss: 64.4299 - output2_loss: 56.6104 - val_loss: 94.8685 - val_output1_loss: 51.5122 - val_output2_loss: 43.3563\n",
            "Epoch 154/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 96.6162 - output1_loss: 49.9945 - output2_loss: 46.6217 - val_loss: 144.4025 - val_output1_loss: 108.4415 - val_output2_loss: 35.9611\n",
            "Epoch 155/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 90.4740 - output1_loss: 50.7015 - output2_loss: 39.7724 - val_loss: 88.2625 - val_output1_loss: 43.9645 - val_output2_loss: 44.2980\n",
            "Epoch 156/300\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 102.7713 - output1_loss: 55.7496 - output2_loss: 47.0216 - val_loss: 119.1175 - val_output1_loss: 60.3014 - val_output2_loss: 58.8161\n",
            "Epoch 157/300\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 349.1487 - output1_loss: 155.0307 - output2_loss: 194.1180 - val_loss: 181.3301 - val_output1_loss: 128.8189 - val_output2_loss: 52.5112\n",
            "Epoch 158/300\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 100.4230 - output1_loss: 55.6407 - output2_loss: 44.7824 - val_loss: 131.7219 - val_output1_loss: 56.9674 - val_output2_loss: 74.7545\n",
            "Epoch 159/300\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 87.4880 - output1_loss: 47.2681 - output2_loss: 40.2199 - val_loss: 93.8509 - val_output1_loss: 49.8632 - val_output2_loss: 43.9876\n",
            "Epoch 160/300\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 94.8049 - output1_loss: 47.8829 - output2_loss: 46.9220 - val_loss: 128.8828 - val_output1_loss: 68.9434 - val_output2_loss: 59.9395\n",
            "Epoch 161/300\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 107.3027 - output1_loss: 59.1378 - output2_loss: 48.1649 - val_loss: 77.7922 - val_output1_loss: 42.7719 - val_output2_loss: 35.0203\n",
            "Epoch 162/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 88.7281 - output1_loss: 46.2692 - output2_loss: 42.4589 - val_loss: 96.6736 - val_output1_loss: 61.5143 - val_output2_loss: 35.1593\n",
            "Epoch 163/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 77.2480 - output1_loss: 41.9166 - output2_loss: 35.3314 - val_loss: 105.2852 - val_output1_loss: 52.8357 - val_output2_loss: 52.4495\n",
            "Epoch 164/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 79.6935 - output1_loss: 42.0858 - output2_loss: 37.6078 - val_loss: 93.5395 - val_output1_loss: 58.1576 - val_output2_loss: 35.3819\n",
            "Epoch 165/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 136.1315 - output1_loss: 72.9773 - output2_loss: 63.1543 - val_loss: 135.2023 - val_output1_loss: 77.6120 - val_output2_loss: 57.5904\n",
            "Epoch 166/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 174.6187 - output1_loss: 88.0598 - output2_loss: 86.5590 - val_loss: 98.7988 - val_output1_loss: 63.6955 - val_output2_loss: 35.1033\n",
            "Epoch 167/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 89.6314 - output1_loss: 46.0919 - output2_loss: 43.5395 - val_loss: 169.0106 - val_output1_loss: 82.5068 - val_output2_loss: 86.5038\n",
            "Epoch 168/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 89.6113 - output1_loss: 45.2354 - output2_loss: 44.3760 - val_loss: 90.1459 - val_output1_loss: 47.8205 - val_output2_loss: 42.3254\n",
            "Epoch 169/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 100.3061 - output1_loss: 53.9343 - output2_loss: 46.3718 - val_loss: 87.5407 - val_output1_loss: 47.3974 - val_output2_loss: 40.1433\n",
            "Epoch 170/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 97.9795 - output1_loss: 52.0806 - output2_loss: 45.8989 - val_loss: 83.0467 - val_output1_loss: 47.5657 - val_output2_loss: 35.4809\n",
            "Epoch 171/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 108.4083 - output1_loss: 56.3980 - output2_loss: 52.0103 - val_loss: 116.7916 - val_output1_loss: 42.1478 - val_output2_loss: 74.6439\n",
            "Epoch 172/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 84.5876 - output1_loss: 43.9102 - output2_loss: 40.6773 - val_loss: 80.0138 - val_output1_loss: 44.5757 - val_output2_loss: 35.4381\n",
            "Epoch 173/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 88.0800 - output1_loss: 46.6656 - output2_loss: 41.4144 - val_loss: 95.8500 - val_output1_loss: 56.0726 - val_output2_loss: 39.7774\n",
            "Epoch 174/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 79.5338 - output1_loss: 41.4234 - output2_loss: 38.1104 - val_loss: 90.5346 - val_output1_loss: 43.4280 - val_output2_loss: 47.1066\n",
            "Epoch 175/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 100.2064 - output1_loss: 50.9347 - output2_loss: 49.2717 - val_loss: 144.5872 - val_output1_loss: 59.8885 - val_output2_loss: 84.6987\n",
            "Epoch 176/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 234.7654 - output1_loss: 104.8470 - output2_loss: 129.9183 - val_loss: 114.7320 - val_output1_loss: 62.1125 - val_output2_loss: 52.6195\n",
            "Epoch 177/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 113.5538 - output1_loss: 56.6662 - output2_loss: 56.8875 - val_loss: 93.6092 - val_output1_loss: 45.1558 - val_output2_loss: 48.4534\n",
            "Epoch 178/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 76.3707 - output1_loss: 40.6446 - output2_loss: 35.7261 - val_loss: 116.2736 - val_output1_loss: 57.4787 - val_output2_loss: 58.7949\n",
            "Epoch 179/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 101.6195 - output1_loss: 50.8244 - output2_loss: 50.7951 - val_loss: 105.2356 - val_output1_loss: 48.8505 - val_output2_loss: 56.3851\n",
            "Epoch 180/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 88.2698 - output1_loss: 43.9492 - output2_loss: 44.3206 - val_loss: 113.5868 - val_output1_loss: 47.5484 - val_output2_loss: 66.0385\n",
            "Epoch 181/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 87.9989 - output1_loss: 45.5190 - output2_loss: 42.4799 - val_loss: 79.0139 - val_output1_loss: 44.0909 - val_output2_loss: 34.9230\n",
            "Epoch 182/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 120.1425 - output1_loss: 62.4881 - output2_loss: 57.6544 - val_loss: 166.2901 - val_output1_loss: 110.9115 - val_output2_loss: 55.3786\n",
            "Epoch 183/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 97.0901 - output1_loss: 49.5335 - output2_loss: 47.5565 - val_loss: 84.4563 - val_output1_loss: 44.1742 - val_output2_loss: 40.2821\n",
            "Epoch 184/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 119.8456 - output1_loss: 57.0688 - output2_loss: 62.7768 - val_loss: 102.3731 - val_output1_loss: 56.2552 - val_output2_loss: 46.1178\n",
            "Epoch 185/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 121.6035 - output1_loss: 58.8454 - output2_loss: 62.7581 - val_loss: 89.2182 - val_output1_loss: 49.8156 - val_output2_loss: 39.4026\n",
            "Epoch 186/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 126.6190 - output1_loss: 57.9892 - output2_loss: 68.6298 - val_loss: 244.7324 - val_output1_loss: 160.6508 - val_output2_loss: 84.0816\n",
            "Epoch 187/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 127.0152 - output1_loss: 60.2520 - output2_loss: 66.7632 - val_loss: 118.0933 - val_output1_loss: 42.7833 - val_output2_loss: 75.3100\n",
            "Epoch 188/300\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 91.4783 - output1_loss: 48.5903 - output2_loss: 42.8879 - val_loss: 81.5591 - val_output1_loss: 46.2995 - val_output2_loss: 35.2596\n",
            "Epoch 189/300\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 69.0211 - output1_loss: 35.8594 - output2_loss: 33.1617 - val_loss: 85.1539 - val_output1_loss: 53.2280 - val_output2_loss: 31.9258\n",
            "Epoch 190/300\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 85.8296 - output1_loss: 44.8252 - output2_loss: 41.0044 - val_loss: 134.9072 - val_output1_loss: 84.8148 - val_output2_loss: 50.0923\n",
            "Epoch 191/300\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 96.0785 - output1_loss: 47.2502 - output2_loss: 48.8283 - val_loss: 76.6670 - val_output1_loss: 36.6343 - val_output2_loss: 40.0326\n",
            "Epoch 192/300\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 139.8214 - output1_loss: 69.9702 - output2_loss: 69.8512 - val_loss: 101.5455 - val_output1_loss: 66.3151 - val_output2_loss: 35.2304\n",
            "Epoch 193/300\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 100.0825 - output1_loss: 52.2866 - output2_loss: 47.7959 - val_loss: 91.3352 - val_output1_loss: 50.9600 - val_output2_loss: 40.3751\n",
            "Epoch 194/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 78.4632 - output1_loss: 38.5287 - output2_loss: 39.9345 - val_loss: 77.6625 - val_output1_loss: 43.1367 - val_output2_loss: 34.5258\n",
            "Epoch 195/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 92.7859 - output1_loss: 45.5542 - output2_loss: 47.2317 - val_loss: 114.8609 - val_output1_loss: 45.7704 - val_output2_loss: 69.0905\n",
            "Epoch 196/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 110.9092 - output1_loss: 55.1218 - output2_loss: 55.7873 - val_loss: 117.4330 - val_output1_loss: 66.2444 - val_output2_loss: 51.1885\n",
            "Epoch 197/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 105.4002 - output1_loss: 53.7279 - output2_loss: 51.6723 - val_loss: 67.5082 - val_output1_loss: 36.5983 - val_output2_loss: 30.9098\n",
            "Epoch 198/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 69.9395 - output1_loss: 35.5321 - output2_loss: 34.4074 - val_loss: 72.8496 - val_output1_loss: 40.9414 - val_output2_loss: 31.9081\n",
            "Epoch 199/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 106.1437 - output1_loss: 53.2558 - output2_loss: 52.8879 - val_loss: 109.7968 - val_output1_loss: 51.9114 - val_output2_loss: 57.8854\n",
            "Epoch 200/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 132.5732 - output1_loss: 63.1312 - output2_loss: 69.4420 - val_loss: 163.6203 - val_output1_loss: 62.0091 - val_output2_loss: 101.6113\n",
            "Epoch 201/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 74.2969 - output1_loss: 37.6788 - output2_loss: 36.6181 - val_loss: 87.0850 - val_output1_loss: 33.7519 - val_output2_loss: 53.3331\n",
            "Epoch 202/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 72.8047 - output1_loss: 37.5006 - output2_loss: 35.3042 - val_loss: 146.4267 - val_output1_loss: 83.0930 - val_output2_loss: 63.3337\n",
            "Epoch 203/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 68.6123 - output1_loss: 34.0057 - output2_loss: 34.6066 - val_loss: 60.7764 - val_output1_loss: 30.8391 - val_output2_loss: 29.9373\n",
            "Epoch 204/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 75.4771 - output1_loss: 36.7268 - output2_loss: 38.7504 - val_loss: 97.9139 - val_output1_loss: 57.6940 - val_output2_loss: 40.2198\n",
            "Epoch 205/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 84.7197 - output1_loss: 38.8398 - output2_loss: 45.8798 - val_loss: 68.4630 - val_output1_loss: 36.3606 - val_output2_loss: 32.1024\n",
            "Epoch 206/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 84.2889 - output1_loss: 40.4603 - output2_loss: 43.8286 - val_loss: 70.4949 - val_output1_loss: 32.0809 - val_output2_loss: 38.4140\n",
            "Epoch 207/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 75.0190 - output1_loss: 37.8625 - output2_loss: 37.1565 - val_loss: 77.4059 - val_output1_loss: 37.8116 - val_output2_loss: 39.5942\n",
            "Epoch 208/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 213.5639 - output1_loss: 108.4319 - output2_loss: 105.1320 - val_loss: 124.3387 - val_output1_loss: 80.1123 - val_output2_loss: 44.2264\n",
            "Epoch 209/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 89.3632 - output1_loss: 43.8571 - output2_loss: 45.5061 - val_loss: 139.9247 - val_output1_loss: 49.9247 - val_output2_loss: 90.0000\n",
            "Epoch 210/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 92.9369 - output1_loss: 43.4543 - output2_loss: 49.4826 - val_loss: 60.4334 - val_output1_loss: 29.6751 - val_output2_loss: 30.7583\n",
            "Epoch 211/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 87.6894 - output1_loss: 41.5575 - output2_loss: 46.1320 - val_loss: 77.7865 - val_output1_loss: 31.9542 - val_output2_loss: 45.8323\n",
            "Epoch 212/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 81.9451 - output1_loss: 39.7372 - output2_loss: 42.2079 - val_loss: 79.3570 - val_output1_loss: 35.0281 - val_output2_loss: 44.3288\n",
            "Epoch 213/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 68.4262 - output1_loss: 30.6070 - output2_loss: 37.8191 - val_loss: 87.0855 - val_output1_loss: 50.0307 - val_output2_loss: 37.0547\n",
            "Epoch 214/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 62.3764 - output1_loss: 31.4187 - output2_loss: 30.9576 - val_loss: 61.3978 - val_output1_loss: 28.5470 - val_output2_loss: 32.8508\n",
            "Epoch 215/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 99.8163 - output1_loss: 48.2290 - output2_loss: 51.5873 - val_loss: 84.1069 - val_output1_loss: 49.3139 - val_output2_loss: 34.7931\n",
            "Epoch 216/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 98.2729 - output1_loss: 48.4517 - output2_loss: 49.8213 - val_loss: 56.9862 - val_output1_loss: 27.9634 - val_output2_loss: 29.0228\n",
            "Epoch 217/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 61.8642 - output1_loss: 30.8283 - output2_loss: 31.0358 - val_loss: 83.0790 - val_output1_loss: 41.2637 - val_output2_loss: 41.8153\n",
            "Epoch 218/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 82.6500 - output1_loss: 39.9237 - output2_loss: 42.7262 - val_loss: 65.0792 - val_output1_loss: 37.9425 - val_output2_loss: 27.1367\n",
            "Epoch 219/300\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 65.2298 - output1_loss: 31.2346 - output2_loss: 33.9952 - val_loss: 59.5766 - val_output1_loss: 32.3740 - val_output2_loss: 27.2026\n",
            "Epoch 220/300\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 79.4772 - output1_loss: 41.5760 - output2_loss: 37.9012 - val_loss: 103.2086 - val_output1_loss: 59.8705 - val_output2_loss: 43.3382\n",
            "Epoch 221/300\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 295.5036 - output1_loss: 132.9593 - output2_loss: 162.5442 - val_loss: 76.5549 - val_output1_loss: 30.0692 - val_output2_loss: 46.4857\n",
            "Epoch 222/300\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 66.7360 - output1_loss: 32.7948 - output2_loss: 33.9413 - val_loss: 69.3792 - val_output1_loss: 26.3600 - val_output2_loss: 43.0192\n",
            "Epoch 223/300\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 84.6504 - output1_loss: 41.4754 - output2_loss: 43.1750 - val_loss: 62.9452 - val_output1_loss: 29.3202 - val_output2_loss: 33.6250\n",
            "Epoch 224/300\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 63.8188 - output1_loss: 32.2141 - output2_loss: 31.6047 - val_loss: 61.1907 - val_output1_loss: 28.3322 - val_output2_loss: 32.8585\n",
            "Epoch 225/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 64.4431 - output1_loss: 30.0117 - output2_loss: 34.4314 - val_loss: 67.4953 - val_output1_loss: 30.1055 - val_output2_loss: 37.3898\n",
            "Epoch 226/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 61.9061 - output1_loss: 30.4767 - output2_loss: 31.4293 - val_loss: 56.2927 - val_output1_loss: 28.4366 - val_output2_loss: 27.8562\n",
            "Epoch 227/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 70.7978 - output1_loss: 34.9640 - output2_loss: 35.8338 - val_loss: 84.1505 - val_output1_loss: 37.4960 - val_output2_loss: 46.6544\n",
            "Epoch 228/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 72.7607 - output1_loss: 36.3440 - output2_loss: 36.4167 - val_loss: 86.2984 - val_output1_loss: 40.8863 - val_output2_loss: 45.4121\n",
            "Epoch 229/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 69.4696 - output1_loss: 34.7863 - output2_loss: 34.6832 - val_loss: 54.4506 - val_output1_loss: 26.9831 - val_output2_loss: 27.4675\n",
            "Epoch 230/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 78.3395 - output1_loss: 36.0284 - output2_loss: 42.3111 - val_loss: 71.9362 - val_output1_loss: 35.2948 - val_output2_loss: 36.6414\n",
            "Epoch 231/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 88.9110 - output1_loss: 44.5332 - output2_loss: 44.3778 - val_loss: 57.0725 - val_output1_loss: 29.1178 - val_output2_loss: 27.9547\n",
            "Epoch 232/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 80.0971 - output1_loss: 37.5837 - output2_loss: 42.5134 - val_loss: 97.5175 - val_output1_loss: 66.8375 - val_output2_loss: 30.6800\n",
            "Epoch 233/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 83.5609 - output1_loss: 40.2227 - output2_loss: 43.3382 - val_loss: 69.5576 - val_output1_loss: 32.7420 - val_output2_loss: 36.8155\n",
            "Epoch 234/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 66.4376 - output1_loss: 32.6227 - output2_loss: 33.8150 - val_loss: 82.7200 - val_output1_loss: 42.4471 - val_output2_loss: 40.2729\n",
            "Epoch 235/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 72.7147 - output1_loss: 34.5531 - output2_loss: 38.1616 - val_loss: 82.8930 - val_output1_loss: 35.8948 - val_output2_loss: 46.9981\n",
            "Epoch 236/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 90.5340 - output1_loss: 45.4403 - output2_loss: 45.0936 - val_loss: 170.5001 - val_output1_loss: 87.8404 - val_output2_loss: 82.6597\n",
            "Epoch 237/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 73.0173 - output1_loss: 36.3403 - output2_loss: 36.6770 - val_loss: 63.2001 - val_output1_loss: 26.1616 - val_output2_loss: 37.0386\n",
            "Epoch 238/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 72.1612 - output1_loss: 36.5134 - output2_loss: 35.6478 - val_loss: 97.0549 - val_output1_loss: 52.2899 - val_output2_loss: 44.7651\n",
            "Epoch 239/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 90.2640 - output1_loss: 41.9347 - output2_loss: 48.3294 - val_loss: 73.6146 - val_output1_loss: 39.2827 - val_output2_loss: 34.3319\n",
            "Epoch 240/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 61.9103 - output1_loss: 30.6007 - output2_loss: 31.3096 - val_loss: 56.6473 - val_output1_loss: 27.2733 - val_output2_loss: 29.3740\n",
            "Epoch 241/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 110.8287 - output1_loss: 51.9900 - output2_loss: 58.8387 - val_loss: 84.5352 - val_output1_loss: 29.7835 - val_output2_loss: 54.7517\n",
            "Epoch 242/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 73.6875 - output1_loss: 35.7265 - output2_loss: 37.9610 - val_loss: 85.6203 - val_output1_loss: 39.1947 - val_output2_loss: 46.4256\n",
            "Epoch 243/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 70.0870 - output1_loss: 33.4255 - output2_loss: 36.6615 - val_loss: 75.1918 - val_output1_loss: 45.9841 - val_output2_loss: 29.2077\n",
            "Epoch 244/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 80.3749 - output1_loss: 40.9274 - output2_loss: 39.4475 - val_loss: 59.7759 - val_output1_loss: 28.4165 - val_output2_loss: 31.3593\n",
            "Epoch 245/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 73.0361 - output1_loss: 37.2706 - output2_loss: 35.7656 - val_loss: 176.7151 - val_output1_loss: 96.9691 - val_output2_loss: 79.7460\n",
            "Epoch 246/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 69.6048 - output1_loss: 34.8101 - output2_loss: 34.7947 - val_loss: 71.7179 - val_output1_loss: 28.6969 - val_output2_loss: 43.0210\n",
            "Epoch 247/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 61.7945 - output1_loss: 30.7566 - output2_loss: 31.0379 - val_loss: 57.2370 - val_output1_loss: 24.5377 - val_output2_loss: 32.6993\n",
            "Epoch 248/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 84.6307 - output1_loss: 40.8808 - output2_loss: 43.7499 - val_loss: 221.2404 - val_output1_loss: 68.2322 - val_output2_loss: 153.0082\n",
            "Epoch 249/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 103.8064 - output1_loss: 49.4426 - output2_loss: 54.3639 - val_loss: 68.1283 - val_output1_loss: 33.2746 - val_output2_loss: 34.8537\n",
            "Epoch 250/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 58.7537 - output1_loss: 28.2034 - output2_loss: 30.5504 - val_loss: 64.5568 - val_output1_loss: 25.2178 - val_output2_loss: 39.3390\n",
            "Epoch 251/300\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 106.6990 - output1_loss: 50.5584 - output2_loss: 56.1406 - val_loss: 84.6865 - val_output1_loss: 33.2330 - val_output2_loss: 51.4535\n",
            "Epoch 252/300\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 81.0461 - output1_loss: 40.4176 - output2_loss: 40.6285 - val_loss: 62.6618 - val_output1_loss: 33.1442 - val_output2_loss: 29.5176\n",
            "Epoch 253/300\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 72.7398 - output1_loss: 34.7640 - output2_loss: 37.9759 - val_loss: 71.2596 - val_output1_loss: 29.2744 - val_output2_loss: 41.9852\n",
            "Epoch 254/300\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 66.0014 - output1_loss: 32.0710 - output2_loss: 33.9304 - val_loss: 82.9519 - val_output1_loss: 36.6210 - val_output2_loss: 46.3309\n",
            "Epoch 255/300\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 227.6278 - output1_loss: 100.8186 - output2_loss: 126.8091 - val_loss: 50.0532 - val_output1_loss: 23.6579 - val_output2_loss: 26.3954\n",
            "Epoch 256/300\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 53.6139 - output1_loss: 25.2753 - output2_loss: 28.3386 - val_loss: 47.5561 - val_output1_loss: 22.6781 - val_output2_loss: 24.8780\n",
            "Epoch 257/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 54.0771 - output1_loss: 25.8593 - output2_loss: 28.2178 - val_loss: 52.9016 - val_output1_loss: 24.3597 - val_output2_loss: 28.5420\n",
            "Epoch 258/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 66.5509 - output1_loss: 31.9124 - output2_loss: 34.6385 - val_loss: 63.7115 - val_output1_loss: 33.1666 - val_output2_loss: 30.5449\n",
            "Epoch 259/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 59.7001 - output1_loss: 28.2768 - output2_loss: 31.4233 - val_loss: 71.6358 - val_output1_loss: 40.2091 - val_output2_loss: 31.4267\n",
            "Epoch 260/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 66.5542 - output1_loss: 30.8547 - output2_loss: 35.6995 - val_loss: 74.0697 - val_output1_loss: 25.5017 - val_output2_loss: 48.5679\n",
            "Epoch 261/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 61.4894 - output1_loss: 28.1720 - output2_loss: 33.3174 - val_loss: 70.2374 - val_output1_loss: 36.6077 - val_output2_loss: 33.6297\n",
            "Epoch 262/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 63.9515 - output1_loss: 31.1670 - output2_loss: 32.7845 - val_loss: 64.3833 - val_output1_loss: 37.8823 - val_output2_loss: 26.5010\n",
            "Epoch 263/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 72.7934 - output1_loss: 34.7911 - output2_loss: 38.0023 - val_loss: 97.7520 - val_output1_loss: 34.8097 - val_output2_loss: 62.9423\n",
            "Epoch 264/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 104.9433 - output1_loss: 46.3327 - output2_loss: 58.6106 - val_loss: 67.1982 - val_output1_loss: 25.9694 - val_output2_loss: 41.2288\n",
            "Epoch 265/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 57.6214 - output1_loss: 26.6977 - output2_loss: 30.9237 - val_loss: 57.0491 - val_output1_loss: 25.6559 - val_output2_loss: 31.3931\n",
            "Epoch 266/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 65.7667 - output1_loss: 31.4052 - output2_loss: 34.3615 - val_loss: 63.3187 - val_output1_loss: 27.7095 - val_output2_loss: 35.6092\n",
            "Epoch 267/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 91.5806 - output1_loss: 42.2998 - output2_loss: 49.2807 - val_loss: 57.7254 - val_output1_loss: 24.9104 - val_output2_loss: 32.8150\n",
            "Epoch 268/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 73.1397 - output1_loss: 36.0788 - output2_loss: 37.0609 - val_loss: 70.8091 - val_output1_loss: 24.9217 - val_output2_loss: 45.8875\n",
            "Epoch 269/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 54.2726 - output1_loss: 24.5064 - output2_loss: 29.7662 - val_loss: 108.1697 - val_output1_loss: 31.3307 - val_output2_loss: 76.8391\n",
            "Epoch 270/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 92.7726 - output1_loss: 39.5387 - output2_loss: 53.2340 - val_loss: 51.7820 - val_output1_loss: 24.8319 - val_output2_loss: 26.9501\n",
            "Epoch 271/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 60.4908 - output1_loss: 28.4821 - output2_loss: 32.0087 - val_loss: 54.2420 - val_output1_loss: 29.1173 - val_output2_loss: 25.1248\n",
            "Epoch 272/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 72.3507 - output1_loss: 34.1641 - output2_loss: 38.1866 - val_loss: 56.6703 - val_output1_loss: 24.1577 - val_output2_loss: 32.5126\n",
            "Epoch 273/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 319.7138 - output1_loss: 133.9165 - output2_loss: 185.7972 - val_loss: 124.3614 - val_output1_loss: 83.3988 - val_output2_loss: 40.9626\n",
            "Epoch 274/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 63.6682 - output1_loss: 31.8627 - output2_loss: 31.8055 - val_loss: 48.3853 - val_output1_loss: 23.0917 - val_output2_loss: 25.2936\n",
            "Epoch 275/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 52.4667 - output1_loss: 24.8888 - output2_loss: 27.5779 - val_loss: 60.6568 - val_output1_loss: 29.3382 - val_output2_loss: 31.3186\n",
            "Epoch 276/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 54.5612 - output1_loss: 26.1082 - output2_loss: 28.4530 - val_loss: 70.2694 - val_output1_loss: 37.4961 - val_output2_loss: 32.7733\n",
            "Epoch 277/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 53.8500 - output1_loss: 24.4418 - output2_loss: 29.4082 - val_loss: 52.1681 - val_output1_loss: 23.6944 - val_output2_loss: 28.4736\n",
            "Epoch 278/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 98.4377 - output1_loss: 42.9194 - output2_loss: 55.5183 - val_loss: 70.2203 - val_output1_loss: 27.9702 - val_output2_loss: 42.2501\n",
            "Epoch 279/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 102.2573 - output1_loss: 43.0784 - output2_loss: 59.1789 - val_loss: 77.0351 - val_output1_loss: 35.1799 - val_output2_loss: 41.8552\n",
            "Epoch 280/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 59.7621 - output1_loss: 28.5682 - output2_loss: 31.1939 - val_loss: 61.1698 - val_output1_loss: 28.4276 - val_output2_loss: 32.7423\n",
            "Epoch 281/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 57.2880 - output1_loss: 27.4392 - output2_loss: 29.8487 - val_loss: 48.7327 - val_output1_loss: 21.9161 - val_output2_loss: 26.8166\n",
            "Epoch 282/300\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 78.4270 - output1_loss: 34.1511 - output2_loss: 44.2759 - val_loss: 93.3725 - val_output1_loss: 66.1416 - val_output2_loss: 27.2309\n",
            "Epoch 283/300\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 67.0376 - output1_loss: 30.6804 - output2_loss: 36.3572 - val_loss: 51.7090 - val_output1_loss: 25.6813 - val_output2_loss: 26.0276\n",
            "Epoch 284/300\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 144.3872 - output1_loss: 64.2474 - output2_loss: 80.1398 - val_loss: 643.2968 - val_output1_loss: 290.7325 - val_output2_loss: 352.5642\n",
            "Epoch 285/300\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 139.5703 - output1_loss: 74.7573 - output2_loss: 64.8130 - val_loss: 49.2377 - val_output1_loss: 23.6515 - val_output2_loss: 25.5863\n",
            "Epoch 286/300\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 64.5209 - output1_loss: 29.9969 - output2_loss: 34.5239 - val_loss: 53.5954 - val_output1_loss: 24.2930 - val_output2_loss: 29.3025\n",
            "Epoch 287/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 51.8275 - output1_loss: 25.0052 - output2_loss: 26.8223 - val_loss: 47.2424 - val_output1_loss: 22.7849 - val_output2_loss: 24.4575\n",
            "Epoch 288/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 59.7397 - output1_loss: 26.8658 - output2_loss: 32.8739 - val_loss: 231.5114 - val_output1_loss: 184.8512 - val_output2_loss: 46.6601\n",
            "Epoch 289/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 78.2400 - output1_loss: 37.0460 - output2_loss: 41.1940 - val_loss: 51.0373 - val_output1_loss: 23.0056 - val_output2_loss: 28.0317\n",
            "Epoch 290/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 54.2158 - output1_loss: 23.4512 - output2_loss: 30.7646 - val_loss: 78.7559 - val_output1_loss: 26.7538 - val_output2_loss: 52.0021\n",
            "Epoch 291/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 60.8613 - output1_loss: 28.9529 - output2_loss: 31.9084 - val_loss: 47.1377 - val_output1_loss: 21.3626 - val_output2_loss: 25.7751\n",
            "Epoch 292/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 67.4484 - output1_loss: 31.4868 - output2_loss: 35.9617 - val_loss: 298.7816 - val_output1_loss: 87.5739 - val_output2_loss: 211.2078\n",
            "Epoch 293/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 69.0426 - output1_loss: 32.2943 - output2_loss: 36.7482 - val_loss: 62.5004 - val_output1_loss: 23.1909 - val_output2_loss: 39.3095\n",
            "Epoch 294/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 57.5284 - output1_loss: 25.4260 - output2_loss: 32.1024 - val_loss: 48.7977 - val_output1_loss: 25.1314 - val_output2_loss: 23.6663\n",
            "Epoch 295/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 93.2949 - output1_loss: 41.3972 - output2_loss: 51.8977 - val_loss: 53.0085 - val_output1_loss: 23.5137 - val_output2_loss: 29.4948\n",
            "Epoch 296/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 140.1859 - output1_loss: 62.3969 - output2_loss: 77.7890 - val_loss: 81.1370 - val_output1_loss: 32.1053 - val_output2_loss: 49.0317\n",
            "Epoch 297/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 77.0073 - output1_loss: 36.9437 - output2_loss: 40.0636 - val_loss: 43.8850 - val_output1_loss: 20.5104 - val_output2_loss: 23.3747\n",
            "Epoch 298/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 61.8550 - output1_loss: 27.9789 - output2_loss: 33.8761 - val_loss: 60.9296 - val_output1_loss: 29.4496 - val_output2_loss: 31.4800\n",
            "Epoch 299/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 72.8934 - output1_loss: 31.0312 - output2_loss: 41.8623 - val_loss: 56.9103 - val_output1_loss: 23.8801 - val_output2_loss: 33.0302\n",
            "Epoch 300/300\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 49.2329 - output1_loss: 22.7722 - output2_loss: 26.4607 - val_loss: 60.8557 - val_output1_loss: 26.2849 - val_output2_loss: 34.5708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 構築したモデルで予測\n",
        "pred1, pred2 = model.predict(x_test)"
      ],
      "metadata": {
        "id": "POt6Ylh5nhUL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0093c63c-85ad-456a-d9de-7e7a855a2776"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 1s 5ms/step\n"
          ]
        }
      ]
    }
  ]
}